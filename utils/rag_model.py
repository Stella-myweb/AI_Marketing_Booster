# utils/rag_model.py
import os
import streamlit as st
from typing import Dict, List, Any, Optional

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader

# ì„¤ì •
from config import OPENAI_API_KEY, LLM_MODEL, TEMPERATURE, DATA_DIR

# ---------------------- ë²¡í„°ìŠ¤í† ì–´ ----------------------
class VectorStore:
    def __init__(self):
        try:
            api_key = st.secrets.get("OPENAI_API_KEY", OPENAI_API_KEY)
            if not api_key:
                st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                raise ValueError("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            self.embeddings = OpenAIEmbeddings(openai_api_key=api_key, model="text-embedding-ada-002")
            self.data_dir = DATA_DIR
            vectorstore_path = os.path.join(self.data_dir, "vectorstore")
            if os.path.exists(vectorstore_path):
                self.vectorstore = FAISS.load_local(vectorstore_path, self.embeddings)
            else:
                self._create_vectorstore()
        except Exception as e:
            st.error(f"ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise

    def _create_vectorstore(self):
        content_dir = os.path.join(self.data_dir, "content")
        if not os.path.exists(content_dir):
            os.makedirs(content_dir, exist_ok=True)
        text_files = [os.path.join(root, file)
                      for root, _, files in os.walk(content_dir)
                      for file in files if file.endswith(".txt")]
        ebook_file = os.path.join(self.data_dir, "ebook_content.txt")
        if os.path.exists(ebook_file):
            text_files.append(ebook_file)
        if not text_files:
            default_file = os.path.join(content_dir, "default_content.txt")
            with open(default_file, "w", encoding="utf-8") as f:
                f.write("""
                ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™”ë¥¼ ìœ„í•œ ê¸°ë³¸ ê°€ì´ë“œ:
                1. ì •í™•í•œ ê¸°ë³¸ ì •ë³´ ì…ë ¥í•˜ê¸°
                2. ë§¤ë ¥ì ì¸ ì´ë¯¸ì§€ ì‚¬ìš©í•˜ê¸°
                3. í‚¤ì›Œë“œ ìµœì í™”í•˜ê¸°
                4. ê³ ê° ë¦¬ë·° ê´€ë¦¬í•˜ê¸°
                5. ì •ê¸°ì ì¸ ì—…ë°ì´íŠ¸í•˜ê¸°
                """)
            text_files.append(default_file)
        documents = []
        for file_path in text_files:
            try:
                loader = TextLoader(file_path, encoding="utf-8")
                documents.extend(loader.load())
            except Exception as e:
                st.warning(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e}")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        split_documents = text_splitter.split_documents(documents)
        self.vectorstore = FAISS.from_documents(split_documents, self.embeddings)
        vectorstore_path = os.path.join(self.data_dir, "vectorstore")
        self.vectorstore.save_local(vectorstore_path)

    def get_relevant_content(self, query: str, n_results: int = 3) -> str:
        try:
            docs = self.vectorstore.similarity_search(query, k=n_results)
            context = "\n\n".join([doc.page_content for doc in docs])
            return context
        except Exception as e:
            st.error(f"ì½˜í…ì¸  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return "ì½˜í…ì¸  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def raw_similarity_search(self, query: str, k: int = 5):
        try:
            if not query:
                return []
            docs = self.vectorstore.similarity_search(query, k=k)
            return docs
        except Exception as e:
            st.error(f"ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# ---------------------- ì§ˆë¬¸/ì§„ë‹¨ ìœ í‹¸ë¦¬í‹° (ê°„ëµí™”) ----------------------
# ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” questions.pyì—ì„œ import í•˜ê±°ë‚˜, ì•„ë˜ì²˜ëŸ¼ í•„ìš”í•œ í•¨ìˆ˜ë§Œ í¬í•¨

def suggest_improvements(result):
    # ì˜ˆì‹œ: ê°œì„ ì  ì¶”ì²œ (ì‹¤ì œ ë¡œì§ì€ questions.py ì°¸ê³ )
    return ["í‚¤ì›Œë“œ ë‹¤ì–‘í™”", "ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ ", "ë¦¬ë·° ê´€ë¦¬ ê°•í™”"]

# ---------------------- RAG ëª¨ë¸ í†µí•© ----------------------
class RAGModel:
    def __init__(self):
        try:
            api_key = st.secrets.get("OPENAI_API_KEY", OPENAI_API_KEY)
            if not api_key:
                st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                raise ValueError("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            self.vector_store = VectorStore()
            self.llm = ChatOpenAI(
                openai_api_key=api_key,
                model_name=LLM_MODEL,
                temperature=TEMPERATURE
            )
        except Exception as e:
            st.error(f"RAG ëª¨ë¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            self.llm = None
            self.vector_store = None

    def generate_response(self, query: str, context: str = None, n_results: int = 3) -> str:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. (1000ì ì´ë‚´, ì´ëª¨í‹°ì½˜ ì†Œì œëª©)
        """
        try:
            if not context and self.vector_store:
                context = self.vector_store.get_relevant_content(query, n_results=n_results)
            elif not context:
                context = """
                ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™” ì¼ë°˜ íŒ:
                1. ë§¤ë ¥ì ì¸ ì´ë¯¸ì§€ ì‚¬ìš©í•˜ê¸°
                2. í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨í•˜ê¸°
                3. ìƒì„¸í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì„¤ëª… ì œê³µí•˜ê¸°
                4. ì •ê¸°ì ì¸ ì½˜í…ì¸  ì—…ë°ì´íŠ¸í•˜ê¸°
                5. ê³ ê° ë¦¬ë·° ê´€ë¦¬í•˜ê¸°
                """
            prompt = f"""
            ë‹¹ì‹ ì€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ 1000ì ì´ë‚´ë¡œ, ì‹¤ì œ ì‚¬ë¡€ì™€ í†µê³„, ìµœì‹  íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ì—¬ ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ê° ì†Œì œëª©ì€ ì´ëª¨í‹°ì½˜(ì˜ˆ: # ğŸ“Š, # ğŸ¯, # ğŸ’¡)ìœ¼ë¡œ êµ¬ë¶„í•´ ì£¼ì„¸ìš”.

            ì°¸ê³  ìë£Œ:
            {context}

            ì§ˆë¬¸: {query}

            ë‹µë³€ í˜•ì‹ ì˜ˆì‹œ:
            # ğŸ“Š í˜„í™© ë¶„ì„\n(í˜„í™©)
            # ğŸ¯ í•µì‹¬ ì „ëµ\n(ì „ëµ)
            # ğŸ’¡ ì‹¤ì „ íŒ\n(íŒ)

            ë‹µë³€:
            """
            response = self.llm.predict(prompt)
            return response[:1000]  # 1000ì ì´ë‚´ë¡œ ì œí•œ
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    def generate_diagnosis_report(self, answers: Dict[str, str], diagnosis_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ìê°€ì§„ë‹¨ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì†Œì œëª©ë³„(í˜„ì¬ ì§„ë‹¨, ì•¡ì…˜ í”Œëœ, ì—…ê·¸ë ˆì´ë“œ íŒ)ë¡œ 800ì ì´ë‚´ì˜ ì „ë¬¸ì  ë¶„ì„ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        try:
            level = diagnosis_result.get("level", {}).get("name", "ê¸°ë³¸")
            improvements = diagnosis_result.get("improvements", {})
            weak_areas = [area['stage'] for area in improvements.get('weak_areas', [])]
            area_contexts = {}
            if self.vector_store:
                for area in weak_areas:
                    query = f"ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ {area} ì „ëµê³¼ ì„±ê³µ ì‚¬ë¡€"
                    area_contexts[area] = self.vector_store.get_relevant_content(query, n_results=2)
            title_map = {
                "ì¸ì‹í•˜ê²Œ í•œë‹¤": "ê²€ìƒ‰ ë…¸ì¶œ ìµœì í™”",
                "í´ë¦­í•˜ê²Œ í•œë‹¤": "í´ë¦­ìœ¨ ë†’ì´ëŠ” ì „ëµ",
                "ë¨¸ë¬¼ê²Œ í•œë‹¤": "ì²´ë¥˜ì‹œê°„ ëŠ˜ë¦¬ëŠ” ë°©ë²•",
                "ì—°ë½ì˜¤ê²Œ í•œë‹¤": "ë¬¸ì˜/ì˜ˆì•½ ì „í™˜ìœ¨ ë†’ì´ê¸°",
                "í›„ì† í”¼ë“œë°± ë°›ëŠ”ë‹¤": "ê³ ê° ì¬ë°©ë¬¸ ìœ ë„ ì „ëµ"
            }
            # ê° ì†Œì œëª©ë³„ë¡œ ë”°ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompts = {
                "current_diagnosis": f"""
                ë‹¹ì‹ ì€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì§„ë‹¨ ê²°ê³¼ì™€ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ\n# ğŸ“Š í˜„ì¬ ì§„ë‹¨\n800ì ì´ë‚´ë¡œ, í˜„í™©ê³¼ ë¬¸ì œì , ê°œì„  í•„ìš”ì„±ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ ì£¼ì„¸ìš”.\nì§„ë‹¨ ë ˆë²¨: {level}\nì§‘ì¤‘ ê°œì„  ì˜ì—­: {', '.join([title_map.get(area, area) for area in weak_areas[:2]])}\nì°¸ê³  ìë£Œ:\n{'\\n'.join([area_contexts.get(area, '') for area in weak_areas[:2]])}
                """,
                "action_plan": f"""
                ë‹¹ì‹ ì€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì§„ë‹¨ ê²°ê³¼ì™€ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ\n# ğŸ¯ ì•¡ì…˜ í”Œëœ\n800ì ì´ë‚´ë¡œ, ì‹¤ì§ˆì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ì „ëµê³¼ ë‹¨ê³„ë³„ ì‹¤ì²œ ë°©ì•ˆì„ ì œì‹œí•´ ì£¼ì„¸ìš”.\nì§„ë‹¨ ë ˆë²¨: {level}\nì§‘ì¤‘ ê°œì„  ì˜ì—­: {', '.join([title_map.get(area, area) for area in weak_areas[:2]])}\nì°¸ê³  ìë£Œ:\n{'\\n'.join([area_contexts.get(area, '') for area in weak_areas[:2]])}
                """,
                "upgrade_tips": f"""
                ë‹¹ì‹ ì€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì§„ë‹¨ ê²°ê³¼ì™€ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ\n# ğŸ’¡ ì—…ê·¸ë ˆì´ë“œ íŒ\n800ì ì´ë‚´ë¡œ, ê²½ìŸì‚¬ì™€ ì°¨ë³„í™”í•  ìˆ˜ ìˆëŠ” ê³ ê¸‰ íŒê³¼ ì‹¤ì „ ì‚¬ë¡€ë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”.\nì§„ë‹¨ ë ˆë²¨: {level}\nì§‘ì¤‘ ê°œì„  ì˜ì—­: {', '.join([title_map.get(area, area) for area in weak_areas[:2]])}\nì°¸ê³  ìë£Œ:\n{'\\n'.join([area_contexts.get(area, '') for area in weak_areas[:2]])}
                """
            }
            results = {}
            for key, prompt in prompts.items():
                results[key] = self.llm.predict(prompt)[:800]
            return {
                "title": "ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™” ì „ëµ ê°€ì´ë“œ",
                "level": level,
                "current_diagnosis": results["current_diagnosis"],
                "action_plan": results["action_plan"],
                "upgrade_tips": results["upgrade_tips"]
            }
        except Exception as e:
            st.error(f"ì§„ë‹¨ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "title": "ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ í”Œë ˆì´ìŠ¤ ìµœì í™” ì „ëµ ê°€ì´ë“œ",
                "level": diagnosis_result.get("level", {}).get("name", "ê¸°ë³¸"),
                "current_diagnosis": "ì§„ë‹¨ ê²°ê³¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "action_plan": "ì§„ë‹¨ ê²°ê³¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "upgrade_tips": "ì§„ë‹¨ ê²°ê³¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            }

    def search_ebook_content(self, query: str, n_results: int = 5) -> List[Dict[str, Any]]:
        try:
            if self.vector_store is None:
                return [{"content": "ì´ë¶ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "source": "ì‹œìŠ¤í…œ"}]
            docs = self.vector_store.raw_similarity_search(query, n_results)
            results = []
            for i, doc in enumerate(docs):
                results.append({
                    "content": doc.page_content,
                    "source": doc.metadata.get("source", f"ì´ë¶ ì„¹ì…˜ {i+1}"),
                    "relevance": round((1.0 - (i * 0.1)), 2)
                })
            return results
        except Exception as e:
            st.error(f"ì´ë¶ ì½˜í…ì¸  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return [{"content": "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "source": "ì‹œìŠ¤í…œ"}]

__all__ = ['RAGModel']